{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr8dlptXKaqL"
      },
      "outputs": [],
      "source": [
        " #import random\n",
        "#import cv2\n",
        "#from keras.preprocessing import image\n",
        "#import scipy.misc as sm\n",
        "#from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD#, Adam\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#import numpy as np\n",
        "#import os\n",
        "#from matplotlib import pyplot\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "# from keras.preprocessing.image import flow_from_directory\n",
        "#from keras.preprocessing.image import img_to_array\n",
        "#from sklearn.preprocessing import LabelBinarizer\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import matplotlib.pyplot as plt\n",
        "#from imutils import paths\n",
        "#import scipy.misc as sm\n",
        "#from keras.models import model_from_json\n",
        "\n",
        "data = ['C:/Users/ankur/.spyder-py3/autosave/data']\n",
        "labels = []\n",
        "IMAGE_DIMS = (224,224,3)\n",
        "\n",
        "print(\"1\")\n",
        "\n",
        "\n",
        "\"\"\"count=0\n",
        "ls1=os.listdir('color1')\n",
        "dic1={}\n",
        "for idx,i in enumerate(ls1):\n",
        "\tdic1[i]=idx\n",
        "\tls2=os.listdir('color1/'+i)\n",
        "\tfor j in ls2:\n",
        "        #im1=np.asarray(sm.imread('color/'+i+'/'+j))\n",
        "        #temp=np.zeros((len(im1),len(im1[0]),len(im1[0][0])   ))\n",
        "\t\tcount=count+1\n",
        "print(count)\n",
        "print(dic1)\n",
        "X=np.zeros((count,224,224,3))\n",
        "Y=np.zeros((count,1))\n",
        "vap=0\n",
        "for idx,i in enumerate(ls1):\n",
        "\tdic1[i]=idx\n",
        "\tls2=os.listdir('color1/'+i)\n",
        "\tfor j in ls2:\n",
        "\t\timg = image.load_img('color1/'+i+'/'+j, target_size=(224, 224))\n",
        "\t\t#im1=np.asarray(sm.imread('color1/'+i+'/'+j))\n",
        "\t\timg = image.img_to_array(img)\n",
        "\t\tprint(img[0])\n",
        "\t\tprint(img.shape)\t\t\n",
        "\t\t#X[vap,:,:,:]=im1\n",
        "\t\t#Y[vap,0]=idx\n",
        "\t\tvap=vap+1\n",
        "\"\"\"\n",
        "# imagePaths = sorted(list(paths.list_images(\"color\")))\n",
        "# i=0\n",
        "# print(\"2\")\n",
        "\n",
        "# for imagePath in imagePaths:\n",
        "\t# load the image, pre-process it, and store it in the data list\n",
        "\t# img = image.load_img(imagePath,target_size=(224,224))\n",
        "\t# img = img_to_array(img)\n",
        "\t# data.append(img)\n",
        "\t# \"\"\"im0=np.asarray(image)\n",
        "\t# data[i,:,:,:]=im0\"\"\"\n",
        "\t# extract set of class labels from the image path and update the\n",
        "\t# labels list\n",
        "\t# l = label = imagePath.split(os.path.sep)[-2]\n",
        "\t# labels.append(l)\n",
        "\n",
        "\n",
        "# print(\"3\")\n",
        "# data = np.array(data, dtype=\"float\") / 255.0\n",
        "\n",
        "# ltb=labels = np.array(labels)\n",
        "# print(labels[16])\n",
        "# lb = LabelBinarizer()\n",
        "# labels = lb.fit_transform(labels)\n",
        "\n",
        "\"\"\"\n",
        "train_labels = os.listdir(\"color\")\n",
        "le = LabelEncoder()\n",
        "le.fit([tl for tl in train_labels])\n",
        "le = LabelEncoder()\n",
        "le_labels = le.fit_transform(ltb)\n",
        "\"\"\"\n",
        "# (trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\t# labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# print(\"4\")\n",
        "# print(trainX.shape)\n",
        "\"\"\"\"\n",
        "ind_train = random.sample(list(range(trainX.shape[0])), 20)\n",
        "trainX = trainX[ind_train]\n",
        "trainY = trainY[ind_train]\n",
        "# test data\n",
        "ind_test = random.sample(list(range(testX.shape[0])), 5)\n",
        "testX = testX[ind_test]\n",
        "testY = testY[ind_test]\n",
        "def resize_data(data):\n",
        "    data_upscaled = np.zeros((data.shape[0], 320, 320, 3))\n",
        "    for i, img in enumerate(data):\n",
        "        large_img = cv2.resize(img, dsize=(320, 320), interpolation=cv2.INTER_CUBIC)\n",
        "        data_upscaled[i] = large_img\n",
        "    return data_upscaled\n",
        "# resize train and  test data\n",
        "x_train_resized = resize_data(trainX)\n",
        "x_test_resized = resize_data(testX)\n",
        "\"\"\"\n",
        "\n",
        "# y_train_hot_encoded = to_categorical(trainY)\n",
        "\n",
        "# y_test_hot_encoded = to_categorical(testY)\n",
        "\n",
        "\"\"\"for i in range(0,len(trainY)):\n",
        "\tprint(y_train_hot_encoded[i])\n",
        "\tprint(\"\\n\")\n",
        "\"\"\"\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "\n",
        "train_generator=aug.flow_from_directory(\n",
        "[10:35, 11/8/2022] Irin: directory=r\"C:/Users/ankur/.spyder-py3/autosave/data/train\",\n",
        "\t\ttarget_size=(224,224),\n",
        "\t\tcolor_mode=\"rgb\",\n",
        "\t\tbatch_size=64,\n",
        "\t\tclass_mode=\"categorical\",\n",
        "\t\tshuffle=True,\n",
        "\t\tseed=None\n",
        "\t)\n",
        "\n",
        "valid_generator=aug.flow_from_directory(\n",
        "\t\tdirectory=r\"C:/Users/ankur/.spyder-py3/autosave/data/test\",\n",
        "\t\ttarget_size=(224,224),\n",
        "\t\tcolor_mode=\"rgb\",\n",
        "\t\tbatch_size=64,\n",
        "\t\tclass_mode=\"categorical\",\n",
        "\t\tshuffle=True,\n",
        "\t\tseed=None\n",
        "\t)\n",
        "\t\n",
        "\n",
        "\n",
        "\t\n",
        "\n",
        "def model(base_model):\n",
        "\t\t\n",
        "\t\n",
        "\tprint(\"5\")\n",
        "\t# get layers and add average pooling layer\n",
        "\tx = base_model.output\n",
        "\tx = GlobalAveragePooling2D()(x)\n",
        "\n",
        "\t# add fully-connected layer\n",
        "\tx = Dense(512, activation='relu')(x)\n",
        "\n",
        "\t# add output layer\n",
        "\tpredictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "\tmodel = Model(inputs=base_model.input, outputs=predictions)\n",
        "\t# fname = \"weights.hdf5\"\n",
        "\t# model.load_weights(fname)\n",
        "\t# freeze pre-trained model area's layer\n",
        "\tfor layer in base_model.layers:\n",
        "\t        layer.trainable = False\n",
        "\n",
        "\t# update the weight that are added\n",
        "\t# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\t# model.fit(x_train, y_train,epochs=4)\n",
        "\n",
        "\t# choose the layers which are updated by training\n",
        "\tlayer_num = len(model.layers)\n",
        "\tprint(layer_num,\" number of layers\")\n",
        "\tfor layer in model.layers[:int(layer_num * 0.7)]:\n",
        "\t\tlayer.trainable = False\n",
        "\n",
        "\tfor layer in model.layers[int(layer_num * 0.7):]:\n",
        "\t\tlayer.trainable = True\n",
        "\t\n",
        "\t# update the weights\n",
        "\tmodel.compile(optimizer=SGD(lr=1e-4,decay=1e-6, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\t\"\"\"history = model.fit_generator(\n",
        "\taug.flow(x_train, y_train,),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX),\n",
        "\tepochs=5, verbose=1)\"\"\"\n",
        "\tSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "\tSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "\thistory=model.fit_generator(generator=train_generator,\n",
        "\t\t\t\t\t\tsteps_per_epoch=STEP_SIZE_TRAIN,\n",
        "\t\t\t\t\t\tvalidation_data=valid_generator,\n",
        "\t\t\t\t\t\tvalidation_steps=STEP_SIZE_VALID,\n",
        "\t\t\t\t\t\t# use_multiprocessing=True,\n",
        "\t\t\t\t\t\t# workers=3,\n",
        "\t\t\t\t\t\t# verbose=2,\n",
        "\t\t\t\t\t\tepochs=100\n",
        "\t\t\t\t\t)\n",
        "\n",
        "\t# print(model.evaluate_generator(generator=valid_generator))\n",
        "\t\n",
        "\tmodel_json = model.to_json()\n",
        "\twith open(\"C:/Users/ankur/.spyder-py3/autosave/model.json\", \"w\") as json_file:\n",
        "\t\tjson_file.write(model_json)\n",
        "\t# serialize weights to HDF5\n",
        "\tmodel.save_weights(\"model.h5\")\n",
        "\tprint(\"Saved model to disk\")\n",
        "\tfname=\"C:/Users/ankur/.spyder-py3/autosave/weights1.hdf5\"\n",
        "\tmodel.save_weights(fname,overwrite=True)\n",
        "\t\n",
        "\t# prediction\n",
        "\t#img = image.load_img(r'C:\\Users\\WASD\\Desktop\\hoga\\color\\Pepper,bell__Bacterial_spot\\29.jpg',target_size=(224,224))\n",
        "\t#img = image.img_to_array(img)\n",
        "\t#img=np.expand_dims(img,axis=0)\n",
        "\t#predictedclass = model.predict(img)\n",
        "\t# print(train_generator.class_indices)\n",
        "\t# predictedclass\n",
        "\t\n",
        "\t#for i in train_generator.class_indices:\n",
        "\t#\tif train_generator.class_indices[i] == np.argmax(predictedclass):\n",
        "\t#\t\tprint(i)\n",
        "\t#\t\tbreak\t\n",
        "\t\t\n",
        "\t\n",
        "\t# history = model.fit(x_train, y_train, epochs=7,batch_size=10)i\n",
        "\t# pyplot.plot(history.history['loss'])\n",
        "\t# pyplot.plot(history.history['val_loss'])\n",
        "\t# pyplot.title('model train vs validation loss')\n",
        "\t# pyplot.ylabel('loss')\n",
        "\t# pyplot.xlabel('epoch')\n",
        "\t# pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "\t# pyplot.show()\n",
        "\n",
        "\t# print(model.summary())\n",
        "\t\n",
        "\t\n",
        "\treturn history\n",
        "\t \n",
        "\n",
        "\n",
        "res_50_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "history=model(res_50_model)"
      ]
    }
  ]
}